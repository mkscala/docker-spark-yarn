master:
  image: hiropppe/hadoop-master:2.6.0
  dns: 172.17.42.1
  ports:
    - "50070:50070" # dfshealth
    - "8088:8088"   # cluster
  volumes:
    - ./volumes/hadoop/dfs/name:/var/hadoop/dfs/name
  user: root
  hostname: hdp1.containers.dev

slave1:
  image: hiropppe/hadoop-slave:2.6.0
  dns: 172.17.42.1
  ports:
    - "50075:50075"
    - "8042:8042"
    - "9200:9200"
    - "9300:9300"
  volumes:
    - ./volumes/hadoop/dfs/data/slave1:/var/hadoop/dfs/data
    - ./volumes/elasticsearch/data/slave1:/var/elasticsearch/data
  hostname: hdp2.containers.dev
  user: root
  mem_limit: 1024m
  environment:
    - MASTER_HOSTNAME=hdp1.containers.dev
  
slave2:
  image: hiropppe/hadoop-slave:2.6.0
  dns: 172.17.42.1
  ports:
    - "51075:50075"
    - "8142:8042"
    - "9201:9200"
    - "9301:9300"
  volumes:
    - ./volumes/hadoop/dfs/data/slave2:/var/hadoop/dfs/data
    - ./volumes/elasticsearch/data/slave2:/var/elasticsearch/data
  hostname: hdp3.containers.dev
  user: root
  mem_limit: 1024m
  environment:
    - MASTER_HOSTNAME=hdp1.containers.dev

spark:
  image: hiropppe/spark-yarn:1.4.1
  dns: 172.17.42.1
  ports:
    - "4040:4040"   # Spark application WebUI
    - "18080:18080" # Spark WebUI 
    - "9999:9999"   # Jupyter
    - "8888:8888"   # td-agent http
    - "8889:8889"   # Jupyter scala 
    - "8989:8989"   # spark-notebook
  volumes:
    - ./volumes/spark-notebook/repos:/var/spark-notebook/repos
    - ./volumes/spark-notebook/notebooks:/usr/local/spark-notebook/notebooks
  hostname: spark.containers.dev
  user: root
  mem_limit: 1024m
  environment:
    - MASTER_HOSTNAME=hdp1.containers.dev
